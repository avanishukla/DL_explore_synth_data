{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TL_ShellShell.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4wBaaNRg682",
        "colab_type": "code",
        "outputId": "3a787385-bcf3-4706-921d-65e37b371ab9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "##mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBAG6IknNt9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import csv\n",
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import time\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as init\n",
        "from sklearn import linear_model\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mM0kZZ043qKk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_path = '/content/drive/My Drive/DL_exp/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBKvPDiGfGn9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### custom dataset class for dataset. read the csv in __init__ . \n",
        "# input : csv file path\n",
        "# output: returns (data,label)\n",
        "class load_dataset(Dataset):\n",
        "    def __init__(self, data_path):\n",
        "        self.samples = pd.read_csv(data_path).values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.samples[idx,:-1] ,self.samples[idx,-1]\n",
        "      \n",
        "### Multilayer Perceptron Model\n",
        "# input : number of features (input), hidden nodes list , number of classes\n",
        "class MultilayerPerceptron(torch.nn.Module):\n",
        "  \n",
        "    def __init__(self,num_features,hidden_nodes_list,num_classes):\n",
        "        super(MultilayerPerceptron, self).__init__()\n",
        "        \n",
        "        num_hidden_layes = len(hidden_nodes_list)\n",
        "        self.hidden = torch.nn.ModuleList()\n",
        "        \n",
        "        self.hidden.append(torch.nn.Linear(num_features, hidden_nodes_list[0]))\n",
        "        for k in range(num_hidden_layes-1):\n",
        "            self.hidden.append(torch.nn.Linear(hidden_nodes_list[k], hidden_nodes_list[k+1]))    \n",
        "        self.hidden.append(torch.nn.Linear(hidden_nodes_list[num_hidden_layes-1], num_classes))\n",
        "        \n",
        "    # input : features\n",
        "    # output: logits , probabilities\n",
        "    def forward(self, x):\n",
        "        out = x\n",
        "        for layer in self.hidden[:-1]:\n",
        "          out = layer(out)\n",
        "          out = F.relu(out)\n",
        "\n",
        "        logits = self.hidden[-1](out)\n",
        "        probas = F.log_softmax(logits, dim=1)\n",
        "        return logits, probas\n",
        "      \n",
        "### weight initialization function\n",
        "# use : model.apply(init_weights)\n",
        "def init_weights(m):\n",
        "  if isinstance(m, torch.nn.Linear):\n",
        "    if initialisation_method=='xavier':\n",
        "      init.xavier_uniform_(m.weight)\n",
        "    if initialisation_method=='he':\n",
        "      init.kaiming_uniform_(m.weight)\n",
        "    m.bias.data.fill_(0.01)\n",
        "    \n",
        "### function to compute the accuracy\n",
        "# input : model, data of type DataLoader\n",
        "# output: cost (log loss), accuracy \n",
        "def compute_accuracy(net, data_loader):\n",
        "    net.eval()\n",
        "    cost, correct_pred, num_examples = 0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for features, targets in data_loader:\n",
        "            features = features.float().to(device)\n",
        "            targets = targets.long().to(device)\n",
        "            logits, probas = net(features)\n",
        "            cost += F.cross_entropy(logits, targets) * targets.size(0)\n",
        "            _, predicted_labels = torch.max(probas, 1)\n",
        "            num_examples += targets.size(0)\n",
        "            correct_pred += (predicted_labels == targets).sum()\n",
        "        return cost/num_examples , correct_pred.float()/num_examples * 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoSuX_AQv3vk",
        "colab_type": "code",
        "outputId": "ddb7ca3f-d657-4802-f8b1-ff1aca351d2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "### Training of model\n",
        "radius_of_sphere_or_inner_shell = 1                  \n",
        "radius_of_outer_shell = 1.1\n",
        "thickness_of_shell = 0\n",
        "dim = 64       \n",
        "data_dir = 'shell_shell_data_version1/'\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "start_time = time.time()\n",
        "          \n",
        "file_name = 'train_in'+ str(radius_of_sphere_or_inner_shell) + '_out'+ str(radius_of_outer_shell) + '_t' + str(thickness_of_shell)+ '_' + str(dim) + 'dim.csv'\n",
        "\n",
        "csv_path = base_path+data_dir+file_name\n",
        "dataset = load_dataset(csv_path)\n",
        "size = len(dataset)\n",
        "train_dataloader = DataLoader(dataset, batch_size=size, shuffle=True)\n",
        "\n",
        "t_h = h_nodes\n",
        "t_i = 1000\n",
        "\n",
        "#architecture\n",
        "num_features  = next(iter(dataset))[0].shape[0]        # Input data dimention\n",
        "# hidden_nodes_list   = [h_nodes]\n",
        "hidden_nodes_list   = [math.ceil(h_nodes*0.1),math.floor(h_nodes*0.9)]                             # List of number of nodes at each hidden layer\n",
        "num_classes   = 2                                      # The number of output classes. In this case, 0 and 1\n",
        "\n",
        "# 'xavier' : Xavier Initialisation\n",
        "# 'he' : He Initialisation\n",
        "initialisation_method = 'xavier'\n",
        "\n",
        "# 'sgd' : SGD (lr) \n",
        "# 'sgdwm' : SGD with Momentum (lr, momentum)\n",
        "# 'adagrad' : AdaGrad\n",
        "# 'adam' : Adam\n",
        "# 'ngd' : Natural gradient descent\n",
        "# 'l1' : L1 Regularisation\n",
        "# 'l2' : L2 Regularisation\n",
        "# 'pathnorm' : PathNorm Regularisation\n",
        "# 'spectralnorm' : Spectral norm Regularisation\n",
        "optimisation_method = 'sgdwm'  \n",
        "\n",
        "# Hyperparameters\n",
        "random_seed = t_i\n",
        "learning_rate = 0.05\n",
        "      \n",
        "torch.manual_seed(random_seed)\n",
        "model = MultilayerPerceptron(num_features,hidden_nodes_list,num_classes)\n",
        "model.apply(init_weights)\n",
        "model = model.to(device)\n",
        "\n",
        "if optimisation_method=='sgd' or optimisation_method=='ngd':\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "if optimisation_method=='sgdwm':\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "if optimisation_method=='adagrad':\n",
        "  optimizer = torch.optim.Adagrad(model.parameters(), lr=learning_rate)\n",
        "if optimisation_method=='adam':\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08)\n",
        "\n",
        "epoch = 0\n",
        "\n",
        "with torch.set_grad_enabled(False):\n",
        "  cost,best_acc = compute_accuracy(model, train_dataloader)\n",
        "\n",
        "count = 1\n",
        "prev_acc=best_acc\n",
        "best_epoch = epoch\n",
        "best_cost = cost\n",
        "\n",
        "while True:\n",
        "    model.train()\n",
        "    for batch_idx, (features, targets) in enumerate(train_dataloader):\n",
        "\n",
        "        features = features.float().to(device)\n",
        "        targets = targets.long().to(device)\n",
        "\n",
        "        ### FORWARD AND BACK PROP\n",
        "        logits, probas = model(features)\n",
        "        cost = F.cross_entropy(logits, targets)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        cost.backward()\n",
        "\n",
        "        ### UPDATE MODEL PARAMETERS\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "    with torch.set_grad_enabled(False):\n",
        "        cost,acc = compute_accuracy(model, train_dataloader)\n",
        "        \n",
        "    epoch+=1\n",
        "    \n",
        "    # Stopping conditions\n",
        "    if prev_acc==acc:\n",
        "      count+=1\n",
        "    else:\n",
        "      prev_acc=acc\n",
        "      count=1\n",
        "    if (epoch>50 and best_acc-acc>=5) or count==20 or epoch==400:\n",
        "    # if (epoch>50 and best_acc-acc>=5) or epoch==400:\n",
        "      break\n",
        "    if acc>best_acc:\n",
        "      best_acc=acc\n",
        "      best_epoch = epoch\n",
        "      best_cost = cost\n",
        "\n",
        "print('Epoch: %03d | Accuracy: %.2f%% | Cost: %.4f' % (epoch,acc,cost))\n",
        "print('Epoch: %03d | Accuracy: %.2f%% | Cost: %.4f' % (best_epoch,best_acc,best_cost))"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 234 | Accuracy: 100.00% | Cost: 0.0695\n",
            "Epoch: 215 | Accuracy: 100.00% | Cost: 0.1207\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ub97yDxlaa3x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a13a9c78-a188-4e6c-ec13-9791026b7f96"
      },
      "source": [
        "# Transfer Learning\n",
        "copy_model_dict = model.state_dict()\n",
        "fl_weight = copy_model_dict['hidden.0.weight'].cpu().numpy()\n",
        "fl_bias = copy_model_dict['hidden.0.bias'].cpu().numpy()\n",
        "sl_weight = copy_model_dict['hidden.1.weight'].cpu().numpy()\n",
        "sl_bias = copy_model_dict['hidden.1.bias'].cpu().numpy()\n",
        "tl_weight = copy_model_dict['hidden.2.weight'].cpu().numpy()\n",
        "tl_bias = copy_model_dict['hidden.2.bias'].cpu().numpy()\n",
        "# print(fl_weight.shape,fl_bias.shape,sl_weight.shape,sl_bias.shape,tl_weight.shape,tl_bias.shape)\n",
        "\n",
        "radius_of_sphere_or_inner_shell = 2              \n",
        "radius_of_outer_shell = 2.1\n",
        "thickness_of_shell = 0\n",
        "dim = 64         \n",
        "data_dir = 'shell_shell_data_version1/'\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "start_time = time.time()\n",
        "          \n",
        "file_name = 'train_in'+ str(radius_of_sphere_or_inner_shell) + '_out'+ str(radius_of_outer_shell) + '_t' + str(thickness_of_shell)+ '_' + str(dim) + 'dim.csv'\n",
        "\n",
        "csv_path = base_path+data_dir+file_name\n",
        "data = pd.read_csv(csv_path).values\n",
        "X = data[:,:-1]\n",
        "y = data[:,-1]\n",
        "\n",
        "X_fl = np.dot(X,np.transpose(fl_weight))+fl_bias\n",
        "X_afl = np.maximum(0,X_fl)\n",
        "X_sl = np.dot(X_afl,np.transpose(sl_weight))+sl_bias\n",
        "X_asl = np.maximum(0,X_sl)\n",
        "logits = np.dot(X_asl,np.transpose(tl_weight))+tl_bias\n",
        "probas = np.exp(logits)/np.sum(np.exp(logits))\n",
        "predicted_labels = np.argmax(probas, axis=1)\n",
        "num_examples = y.shape[0]\n",
        "correct_pred = (predicted_labels == y).sum()\n",
        "print(correct_pred/num_examples * 100)\n",
        "\n",
        "input_X = X_fl\n",
        "\n",
        "lm = linear_model.SGDClassifier(loss='log',max_iter=1000, tol=1e-5,random_state=10,learning_rate='constant',eta0=0.005)\n",
        "lm.fit(input_X, y)\n",
        "y_lm = lm.predict(input_X)\n",
        "print (metrics.accuracy_score(y, y_lm)*100)\n",
        "\n",
        "svm = LinearSVC(C=1,random_state=0, tol=1e-5)\n",
        "svm.fit(input_X, y)\n",
        "y_svm = svm.predict(input_X)\n",
        "print (metrics.accuracy_score(y, y_svm)*100)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "52.6\n",
            "60.8\n",
            "63.800000000000004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMWuhCSagJp3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "outputId": "d2156bb1-d85b-462f-a117-f1f218da488d"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "### Data for training\n",
        "radius_of_sphere_or_inner_shell = 1                  \n",
        "radius_of_outer_shell = 1.6\n",
        "thickness_of_shell = 0\n",
        "dim = 4       \n",
        "data_dir = 'shell_shell_data_version1/'\n",
        "         \n",
        "file_name = 'train_in'+ str(radius_of_sphere_or_inner_shell) + '_out'+ str(radius_of_outer_shell) + '_t' + str(thickness_of_shell)+ '_' + str(dim) + 'dim.csv'\n",
        "csv_path = base_path+data_dir+file_name\n",
        "dataset = load_dataset(csv_path)\n",
        "size = len(dataset)\n",
        "train_dataloader = DataLoader(dataset, batch_size=size, shuffle=True)\n",
        "\n",
        "## Data for testing\n",
        "radius_of_sphere_or_inner_shell = 2             \n",
        "radius_of_outer_shell = 2.6\n",
        "          \n",
        "file_name = 'train_in'+ str(radius_of_sphere_or_inner_shell) + '_out'+ str(radius_of_outer_shell) + '_t' + str(thickness_of_shell)+ '_' + str(dim) + 'dim.csv'\n",
        "csv_path = base_path+data_dir+file_name\n",
        "data = pd.read_csv(csv_path).values\n",
        "X = data[:,:-1]\n",
        "y = data[:,-1]\n",
        "\n",
        "## \n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "h_nodes = 512\n",
        "fraction = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
        "trained = []\n",
        "test = []\n",
        "svc_fl = []\n",
        "svc_sl = []\n",
        "sgd_fl = []\n",
        "sgd_sl = []\n",
        "\n",
        "for frac in fraction:\n",
        "  #architecture\n",
        "  num_features  = next(iter(dataset))[0].shape[0]        # Input data dimention\n",
        "  hidden_nodes_list   = [math.ceil(h_nodes*frac),math.floor(h_nodes*(1-frac))]     # List of number of nodes at each hidden layer\n",
        "  num_classes   = 2                                      # The number of output classes. In this case, 0 and 1\n",
        "\n",
        "  # 'xavier' : Xavier Initialisation\n",
        "  # 'he' : He Initialisation\n",
        "  initialisation_method = 'xavier'\n",
        "\n",
        "  # 'sgd' : SGD (lr) \n",
        "  # 'sgdwm' : SGD with Momentum (lr, momentum)\n",
        "  # 'adagrad' : AdaGrad\n",
        "  # 'adam' : Adam\n",
        "  # 'ngd' : Natural gradient descent\n",
        "  # 'l1' : L1 Regularisation\n",
        "  # 'l2' : L2 Regularisation\n",
        "  # 'pathnorm' : PathNorm Regularisation\n",
        "  # 'spectralnorm' : Spectral norm Regularisation\n",
        "  optimisation_method = 'sgdwm'  \n",
        "\n",
        "  # Hyperparameters\n",
        "  random_seed = 1000\n",
        "  learning_rate = 0.05\n",
        "        \n",
        "  torch.manual_seed(random_seed)\n",
        "  model = MultilayerPerceptron(num_features,hidden_nodes_list,num_classes)\n",
        "  model.apply(init_weights)\n",
        "  model = model.to(device)\n",
        "\n",
        "  if optimisation_method=='sgd' or optimisation_method=='ngd':\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "  if optimisation_method=='sgdwm':\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "  if optimisation_method=='adagrad':\n",
        "    optimizer = torch.optim.Adagrad(model.parameters(), lr=learning_rate)\n",
        "  if optimisation_method=='adam':\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08)\n",
        "\n",
        "  epoch = 0\n",
        "\n",
        "  with torch.set_grad_enabled(False):\n",
        "    cost,best_acc = compute_accuracy(model, train_dataloader)\n",
        "\n",
        "  count = 1\n",
        "  prev_acc=best_acc\n",
        "  best_epoch = epoch\n",
        "  best_cost = cost\n",
        "\n",
        "  while True:\n",
        "      model.train()\n",
        "      for batch_idx, (features, targets) in enumerate(train_dataloader):\n",
        "\n",
        "          features = features.float().to(device)\n",
        "          targets = targets.long().to(device)\n",
        "\n",
        "          ### FORWARD AND BACK PROP\n",
        "          logits, probas = model(features)\n",
        "          cost = F.cross_entropy(logits, targets)\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          cost.backward()\n",
        "\n",
        "          ### UPDATE MODEL PARAMETERS\n",
        "          optimizer.step()\n",
        "\n",
        "\n",
        "      with torch.set_grad_enabled(False):\n",
        "          cost,acc = compute_accuracy(model, train_dataloader)\n",
        "          \n",
        "      epoch+=1\n",
        "      \n",
        "      # Stopping conditions\n",
        "      if prev_acc==acc:\n",
        "        count+=1\n",
        "      else:\n",
        "        prev_acc=acc\n",
        "        count=1\n",
        "      if (epoch>50 and best_acc-acc>=5) or count==20 or epoch==400:\n",
        "      # if (epoch>50 and best_acc-acc>=5) or epoch==400:\n",
        "        break\n",
        "      if acc>best_acc:\n",
        "        best_acc=acc\n",
        "        best_epoch = epoch\n",
        "        best_cost = cost\n",
        "\n",
        "  # print('Epoch: %03d | Accuracy: %.2f%% | Cost: %.4f' % (best_epoch,best_acc,best_cost))\n",
        "  trained.append(best_acc)\n",
        "\n",
        "  # Transfer Learning\n",
        "  copy_model_dict = model.state_dict()\n",
        "  fl_weight = copy_model_dict['hidden.0.weight'].cpu().numpy()\n",
        "  fl_bias = copy_model_dict['hidden.0.bias'].cpu().numpy()\n",
        "  sl_weight = copy_model_dict['hidden.1.weight'].cpu().numpy()\n",
        "  sl_bias = copy_model_dict['hidden.1.bias'].cpu().numpy()\n",
        "  tl_weight = copy_model_dict['hidden.2.weight'].cpu().numpy()\n",
        "  tl_bias = copy_model_dict['hidden.2.bias'].cpu().numpy()\n",
        "\n",
        "  X_fl = np.dot(X,np.transpose(fl_weight))+fl_bias\n",
        "  X_afl = np.maximum(0,X_fl)\n",
        "  X_sl = np.dot(X_afl,np.transpose(sl_weight))+sl_bias\n",
        "  X_asl = np.maximum(0,X_sl)\n",
        "  logits = np.dot(X_asl,np.transpose(tl_weight))+tl_bias\n",
        "  probas = np.exp(logits)/np.sum(np.exp(logits))\n",
        "  predicted_labels = np.argmax(probas, axis=1)\n",
        "  num_examples = y.shape[0]\n",
        "  correct_pred = (predicted_labels == y).sum()\n",
        "  test.append(correct_pred/num_examples * 100)\n",
        "\n",
        "  input_X = X_fl\n",
        "\n",
        "  lm = linear_model.SGDClassifier(loss='log',max_iter=1000, tol=1e-5,random_state=10,learning_rate='constant',eta0=0.005)\n",
        "  lm.fit(input_X, y)\n",
        "  y_lm = lm.predict(input_X)\n",
        "  sgd_fl.append(metrics.accuracy_score(y, y_lm)*100)\n",
        "\n",
        "  svm = LinearSVC(C=1,random_state=0, tol=1e-5)\n",
        "  svm.fit(input_X, y)\n",
        "  y_svm = svm.predict(input_X)\n",
        "  svc_fl.append(metrics.accuracy_score(y, y_svm)*100)\n",
        "\n",
        "  input_X = X_sl\n",
        "\n",
        "  lm = linear_model.SGDClassifier(loss='log',max_iter=1000, tol=1e-5,random_state=10,learning_rate='constant',eta0=0.005)\n",
        "  lm.fit(input_X, y)\n",
        "  y_lm = lm.predict(input_X)\n",
        "  sgd_sl.append(metrics.accuracy_score(y, y_lm)*100)\n",
        "\n",
        "  svm = LinearSVC(C=1,random_state=0, tol=1e-5)\n",
        "  svm.fit(input_X, y)\n",
        "  y_svm = svm.predict(input_X)\n",
        "  svc_sl.append(metrics.accuracy_score(y, y_svm)*100)\n",
        "print(trained)\n",
        "print(test)\n",
        "print(svc_fl)\n",
        "print(svc_sl)\n",
        "print(sgd_fl)\n",
        "print(sgd_sl)\n",
        "\n",
        "xaxis = [int(f*100) for f in fraction]\n",
        "fig = plt.figure()\n",
        "plt.plot(xaxis,svc_fl,label='fl_svm')\n",
        "plt.plot(xaxis,svc_sl,label=' sl_svm')\n",
        "plt.plot(xaxis,sgd_fl,label='fl_sgd')\n",
        "plt.plot(xaxis,sgd_sl,label=' sl_sgd')\n",
        "plt.plot(xaxis,test,label='test')\n",
        "plt.plot(xaxis,trained,label='trained')\n",
        "axes = plt.gca()\n",
        "axes.set_xlim([0,130])\n",
        "plt.legend(loc='lower right')\n",
        "plt.xlabel('% nodes in FL')\n",
        "plt.ylabel('accuracy')\n",
        "fig.suptitle('(1,1.6)-(2,2.6) 4 dim', fontsize=14)\n",
        "fig.savefig(base_path+'result/4.jpg')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(100., device='cuda:0'), tensor(100., device='cuda:0'), tensor(100., device='cuda:0'), tensor(100., device='cuda:0'), tensor(100., device='cuda:0'), tensor(100., device='cuda:0'), tensor(100., device='cuda:0'), tensor(100., device='cuda:0'), tensor(100., device='cuda:0')]\n",
            "[50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0]\n",
            "[51.800000000000004, 51.800000000000004, 51.800000000000004, 51.800000000000004, 51.800000000000004, 51.800000000000004, 51.800000000000004, 51.800000000000004, 51.800000000000004]\n",
            "[100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n",
            "[49.4, 51.0, 50.0, 50.6, 50.0, 50.0, 50.4, 49.8, 49.6]\n",
            "[100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEjCAYAAAAomJYLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HrmiP6XWctD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}